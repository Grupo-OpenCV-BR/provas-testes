{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metologias\n",
    "<h5> Denoising: </h5>\n",
    "Para Filtrar os ruídos indesejáveis na imagem, utilizei ajustes no brilho e contraste da imagem assim foi possível obter uma imagem relativamente boa sem perder muitas features que pode correr com erosion, blur ou median filter.\n",
    "<h5> Skew Angle:</h5>\n",
    "Para Rotacionar o texto utilzei a detecção de linhas com base no texto e pelo angulo da ultima linha rotacionei a imagem.\n",
    "<h5>Outros testes:</h5>\n",
    "Utilizei Autoencoder para testes de Denoising, mas pela imagem ser de alta resolução e as limitações de processamento do Autoencoder (Dimensão Latente) não obtive bons resultados (deixei algumas amostras na pasta Decoder).\n",
    "Uma possibilidade seria utilizar autoencoder em baixa resolução e utilizar super resolução para reconstruir em uma imagem maior (50x50) para (100x100) em um custo médio de processamento.\n",
    "\n",
    "# Resolução do problema na penultima célula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"noisy_data/104.png\", 0)\n",
    "median = cv2.medianBlur(image,35)\n",
    "cleaned = cv2.subtract(median, image)\n",
    "cleaned = cv2.bitwise_not(cleaned)\n",
    "alpha = 2.0\n",
    "beta = -160\n",
    "cleaned = alpha * cleaned + beta\n",
    "cleaned = np.clip(cleaned, 0, 255).astype(np.uint8)\n",
    "cv2.imshow(\"Original\",image)\n",
    "cv2.imshow(\"Background\",median)\n",
    "cv2.imshow(\"Cleaned\",cleaned)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "median = cv2.medianBlur(image,35)\n",
    "teste2 = cv2.subtract(median, image)\n",
    "median2 = cv2.medianBlur(teste2,25)\n",
    "teste3 = cv2.subtract(median2,teste2)\n",
    "whited2 = cv2.bitwise_not(teste2)\n",
    "alpha = 2.0\n",
    "beta = -160\n",
    "new = alpha * whited2 + beta\n",
    "new = np.clip(new, 0, 255).astype(np.uint8)\n",
    "#teste3 = (teste3 - median)/median\n",
    "#median2 = cv2.medianBlur(teste3,25)\n",
    "#teste4 = cv2.subtract(median2,teste2)\n",
    "#teste3 = 1 * teste3 + 127\n",
    "#whited = cv2.bitwise_not(teste2)\n",
    "#whited2 = cv2.bitwise_not(teste3)\n",
    "#whited = 1.25 * whited + -254\n",
    "#whited = (whited - np.min(whited)) * (np.max(whited) - np.min(whited))\n",
    "#ran = range(teste)\n",
    "#teste3 = (teste3 - 0) * (252)\n",
    "cv2.imshow(\"Original\",new)\n",
    "cv2.imshow(\"teste3\",teste2)\n",
    "cv2.imshow(\"background\",teste3)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.linalg import norm\n",
    "\n",
    "def brightness(img):\n",
    "    if len(img.shape) == 3:\n",
    "        # Colored RGB or BGR (*Do Not* use HSV images with this function)\n",
    "        # create brightness with euclidean norm\n",
    "        return np.average(norm(img, axis=2)) / np.sqrt(3)\n",
    "    else:\n",
    "        # Grayscale\n",
    "        return np.average(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.46571254673542"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teste3.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9384615384615385\n"
     ]
    }
   ],
   "source": [
    "min1 = np.min(teste3).astype(np.float64) \n",
    "max1 = np.max(teste3).astype(np.float64) \n",
    "contrast = (max1-min1)/(max1+min1)\n",
    "print(contrast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(teste3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "252.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184.6636435055866"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brightness(teste3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202.78883554469274"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brightness(median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brightness = 202-184\n",
    "contrast = 30\n",
    "img = teste3 * (contrast/127+1) - contrast + brightness\n",
    "img = np.clip(img, 0, 255)\n",
    "img = np.uint8(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(whited)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222\n"
     ]
    }
   ],
   "source": [
    "print(np.max(whited) - np.min(whited))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(new, 30, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"EdgedImage\",edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "dilation = cv2.dilate(new,(2,2),iterations = 1)\n",
    "opening = cv2.morphologyEx(dilation, cv2.MORPH_OPEN, (3,3))\n",
    "closing = cv2.morphologyEx(new, cv2.MORPH_CLOSE, (3,3))\n",
    "gradient = cv2.morphologyEx(new, cv2.MORPH_GRADIENT, (3,3))\n",
    "opening2 = cv2.morphologyEx(gradient, cv2.MORPH_OPEN, (3,3))\n",
    "opening2 = cv2.morphologyEx(opening2, cv2.MORPH_CLOSE, (3,3))\n",
    "op_thresh = cv2.threshold(opening2, 0, 255, cv2.THRESH_BINARY)[1]\n",
    "opening2 = cv2.bitwise_not(op_thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Opening\",opening)\n",
    "cv2.imshow(\"Closing\",closing)\n",
    "cv2.imshow(\"gradient\",gradient)\n",
    "cv2.imshow(\"Opening2\",opening2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "contours, _ = cv2.findContours(edged, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnt = max(contours, key=cv2.contourArea)\n",
    "x,y,w,h = cv2.boundingRect(cnt)\n",
    "cv2.rectangle(image2, (x,y), (x+w, y+h), (255,255,0), 1)\n",
    "cv2.imshow('img', image2)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Original\",median)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78\n"
     ]
    }
   ],
   "source": [
    "rho = 1  # distance resolution in pixels of the Hough grid\n",
    "theta = np.pi / 180  # angular resolution in radians of the Hough grid\n",
    "threshold = 15  # minimum number of votes (intersections in Hough grid cell)\n",
    "min_line_length = 300  # minimum number of pixels making up a line\n",
    "max_line_gap = 30  # maximum gap in pixels between connectable line segments\n",
    "line_image = np.copy(new) * 0  # creating a blank to draw lines on\n",
    "# Run Hough on edge detected image\n",
    "# Output \"lines\" is an array containing endpoints of detected line segments\n",
    "lines = cv2.HoughLinesP(edged, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "print(len(lines))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for line in lines:\n",
    "    for x1,y1,x2,y2 in line:\n",
    "        cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "        last_angle = int(math.atan((y1-y2)/(x2-x1))*180/math.pi)\n",
    "        angle = last_angle*-1\n",
    "print(angle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"lines\",line_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "angle = angle + 90 if angle < -45 else angle\n",
    "(h, w) = new.shape[0:2]\n",
    "center = (w // 2, h // 2)\n",
    "M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "corrected_image = cv2.warpAffine(new, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"lines\",corrected_image)\n",
    "cv2.imshow(\"new\",new)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Função de Cleanup e Skew Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skew_img(image_path, output_path):\n",
    "    files = []\n",
    "    ext = (\"*.png\", \"*.jpg\", \"*.jpeg\")\n",
    "    for extensions in ext:\n",
    "        files.extend(glob.glob(os.path.join(image_path, extensions)))\n",
    "    print(\"Total de Arquivos %s\"%len(files))\n",
    "    for file in files:\n",
    "        lines = None\n",
    "        name = os.path.basename(file)\n",
    "        image = cv2.imread(file)\n",
    "        median = cv2.medianBlur(image,35)\n",
    "        cleaned = cv2.subtract(median, image)\n",
    "        cleaned = cv2.bitwise_not(cleaned)\n",
    "        alpha = 2.0\n",
    "        beta = -160\n",
    "        cleaned = alpha * cleaned + beta\n",
    "        cleaned = np.clip(cleaned, 0, 255).astype(np.uint8)\n",
    "        edged = cv2.Canny(cleaned, 30, 200)\n",
    "        rho = 1\n",
    "        theta = np.pi / 180\n",
    "        threshold = 15\n",
    "        min_line_length = 300\n",
    "        max_line_gap = 20\n",
    "        line_image = np.copy(image) * 0\n",
    "        lines = cv2.HoughLinesP(edged, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "        if lines is not None:\n",
    "            for line in lines:\n",
    "                for x1,y1,x2,y2 in line:\n",
    "                    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "                    last_angle = int(math.atan((y1-y2)/(x2-x1))*180/math.pi)\n",
    "                    angle = last_angle*-1\n",
    "            angle = angle + 90 if angle < -45 else angle\n",
    "            (h, w) = image.shape[0:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, angle, 1.0)\n",
    "            corrected_image = cv2.warpAffine(cleaned, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "            cv2.imwrite(os.path.join(output_path,name), corrected_image)\n",
    "        else:\n",
    "            rho = 1\n",
    "            theta = np.pi / 180\n",
    "            threshold = 15\n",
    "            min_line_length = 300\n",
    "            max_line_gap = 30\n",
    "            line_image = np.copy(image) * 0\n",
    "            lines = cv2.HoughLinesP(edged, rho, theta, threshold, np.array([]),\n",
    "                    min_line_length, max_line_gap)\n",
    "            angles = []\n",
    "            for line in lines:\n",
    "                for x1,y1,x2,y2 in line:\n",
    "                    cv2.line(line_image,(x1,y1),(x2,y2),(255,0,0),5)\n",
    "                    last_angle = int(math.atan((y1-y2)/(x2-x1))*180/math.pi)\n",
    "                    angle = last_angle*-1\n",
    "                    angles.append(angle)\n",
    "            m_angle = sum(angles) / len(angles) \n",
    "            print(angle)\n",
    "            print(m_angle)\n",
    "            angle = angle + 90 if angle < -45 else angle\n",
    "            m_angle = m_angle + 90 if m_angle < -45 else m_angle\n",
    "            (h, w) = image.shape[0:2]\n",
    "            center = (w // 2, h // 2)\n",
    "            M = cv2.getRotationMatrix2D(center, m_angle, 1.0)\n",
    "            corrected_image = cv2.warpAffine(cleaned, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)\n",
    "            cv2.imwrite(os.path.join(output_path,name), corrected_image)\n",
    "    print(\"Arquivos Escritos!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de Arquivos 144\n",
      "2\n",
      "2.1176470588235294\n",
      "Arquivos Escritos!!\n"
     ]
    }
   ],
   "source": [
    "skew_img(\"./noisy_data\", \"./best_clean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
